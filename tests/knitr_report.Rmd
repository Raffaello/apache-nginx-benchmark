---
title: "Apache httpd Vs Nginx"
author: "Raffaello Bertini"
date: "14 December 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
```
## Apache Httpd Vs Nginx

Using Apache Benchmark utility, `ab`, i will perform a series of request against apache and nginx of the same php page script, using bcmath and doing some computations. The results are stored from redirecting the stdout to some '*.log' files.

### Parsing the logs

To parse and extract data from the logs file i will use some helper function.

I will use a utility function to generate the file name to be read, it is shared between different scripts. So it will be included from an external file:

```{r init1, include = T}
source("./shared_utils.r")
```

What I have just loaded is this function:
```{r init1b, include = T}
print (generateLogFileName)
```

and this are the `-n` and `-c` parameters used with the `ab` program:
```{r init1c, include=T}
print(tests)
```

I use this function to read and parse the data I want directly from the log files, if an error occur during the read operation, it will return an empty equivalent vector of the expected result:

```{r init2, include = T}
extractDataFromLogTable <- function (logFileNamePrefix, n, c) {
  fn <- generateLogFileName(n, c, logFileNamePrefix)
  #print(fn)
  tryCatch({
  t <- read.table(fn, sep=":", skip=6, comment.char='', fill=T, stringsAsFactors=FALSE, strip.white = TRUE)
  
#1.   webServer <- t$V2[1]
#2.   docLength <- t$V2[5]
#3.   concurrencyLevel <- t$V2[6]
#4.X  totTime <- t$V2[7]
#5.   reqCompleted <- t$V2[8]
#6.X  reqFailed <- t$V2[9]
#7.   writeErrors <- t$V2[10]
#8.   keepAlive <- t$V2[12]  
#9.   reqPerSec <- t$V2[13]
#10.   timePerReq <- t$V2[14]
#11.  timePerReq2 <- t$V2[15]
#12.  transRate <- t$V2[16]
#13.  total <-t$V2[22]
  t$V2[c(1,5:10,12:16,22)]
  }, error = function(err) {
     r <-rep(0,12)
     r[c(1,4)] <- ''
  })
}
```

The choice to do not preload all the data and do the processing after, it is due to having an approch to load only the data required at the time of the computation, (with R is still required to explicitly `rm` variables from the environments(). The file should be cached by OS if memory is available so there is no much such performance lost at least for this case, except reparsing the file each time, but it is a good trade off.

here we are extracting the webservers used:

```{r webServerNames, include=T}
webServers_ <- c("nginx", "httpd")
webTests <- c("index.php", "bcmath.php")
webServers <- apply(expand.grid(webServers_, webTests), 1, function(x) {paste(x[1],x[2],sep="-")})
#webServerNames <- c(
#    extractDataFromLogTable(webServers[1],tests$n[1], tests$c[1])[1],
#    extractDataFromLogTable(webServers[2],tests$n[1], tests$c[1])[1]
#)
webServerNames <- webServers
print(webServerNames)
```

and here the column names, used also for axis x-labeling:
```{r colNames, include=T}
colNames <- paste(paste('n',tests$n, sep=''), paste('c',tests$c, sep=''), sep='-')
print(colNames)
```


## plots and data

The first plot is the error of the responses:

```{r reqFailedFun, include=T, echo=F}
compareRequestFailed <- function(n, c) {
  unlist(lapply(webServers, function(x){ as.numeric(extractDataFromLogTable(x,n,c)[6])}))
}
```

```{r barplotReqFailed, include=T, echo=F}
reqFailedCmp <- apply(tests, 1, function(x) {
  compareRequestFailed(x[1], x[2])
})
rownames(reqFailedCmp) <- webServers
colnames(reqFailedCmp) <- colNames

library(RColorBrewer)
cols<-brewer.pal(n=4,name="Set1")
#cols <- c("red", "blue")
mainTitle <- "Request Failed"
ymax <- max(reqFailedCmp, na.rm = T)
reqFailedCmpCleaned <- reqFailedCmp
reqFailedCmpCleaned[is.na(reqFailedCmp)] <- ymax
g_range <- range(0, ymax)
print (g_range)
barplot(reqFailedCmpCleaned, main=mainTitle, col=cols, beside = T, names.arg=paste(paste('n',tests$n, sep=''), paste('c',tests$c, sep=''), sep='-'), las=2) #axes = F, ann = F)
dt <- dim(tests)
box()
legend("topleft", webServerNames, bty="n", fill=cols);
kable(reqFailedCmp)
```

```{r totReqFailed, include=T, echo=F}
percentageTotReqFailed <- (apply(reqFailedCmp, 1, function(x){ sum(x, na.rm=F)/sum(tests$n)*100 }))
names(percentageTotReqFailed) <- webServers
#cols <- c("red","blue")
barplot(percentageTotReqFailed, main="Tot Requests failed (%)", col=cols)
#legend("topleft", webServerNames, bty="n", fills=cols)
legend("topright", webServerNames, bty="n", fill=cols);
print(percentageTotReqFailed)
```

The second one is total time to complete the requests.

I am using another helper function to extract and parse data:
```{r init3, include = T}
compareTimeResults <- function (n, c, webServers) {
  tn <- extractDataFromLogTable(webServers[1], n, c)
  th <- extractDataFromLogTable(webServers[2], n, c)

  timeCmp <- c(c(as.numeric(strsplit(tn[4], ' ', T)[[1]][1])), as.numeric(strsplit(th[4], ' ', T)[[1]][1]))
}
```

here the plot:
```{r timeCmpPlot, include=T, echo=F}

timesCmp <- apply(tests, 1, function(x) {
  compareTimeResults(x[1], x[2], webServers)
})
rownames(timesCmp) <- webServers
colnames(timesCmp) <- colNames

plotTimeCmp <- function(timesCmp) {
  #cols <- c('red', 'blue')
  mainTitle <- "Total Time (s)"
  ymax <- max(timesCmp, na.rm = T)
  g_range <- range(0, ymax)
  #print (g_range)
  plot(timesCmp[1,], type='o', main=mainTitle, col=cols[1], lty=1, pch=1, ylim = g_range, axes = F, ann = F)
  dt <- dim(tests)
  axis(1, at=1:dt[1], lab=colNames, las=2)
  axis(2, las=1)
  box()
  lines(timesCmp[2,], type='o', col=cols[2], lty=2, pch=2)
  legend(1,ymax, webServerNames, col=c("red","blue"), cex=0.8, lty=1:2, pch=1:2)
  
  #print(timesCmp)
}

plotTimeCmp(timesCmp)
kable(timesCmp)
```

### Cleaning time data

Now I am keeping only the data that was completely succesful:
```{r cleaningTimeCmp, include=T}
timesCmpFilter <- reqFailedCmp == 0 & !is.na(reqFailedCmp)
cleanedTimesCmp <- rbind(timesCmp[1, timesCmpFilter[1,]], timesCmp[2, timesCmpFilter[2,]])
rownames(cleanedTimesCmp) <- webServers
rm(timesCmpFilter)
```

the resulting plot:
```{r cleanedTimeCmp, include=T, echo=F}
kable(cleanedTimesCmp)
plotTimeCmp(cleanedTimesCmp)

```
